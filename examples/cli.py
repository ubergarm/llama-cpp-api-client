#!/usr/bin/env python3

import asyncio

from llama_cpp_api_client import chat_to_prompt, stream_response


async def main():
    print("TODO: Create a bare bones https://github.com/Textualize/rich based CLI")


if __name__ == "__main__":
    asyncio.run(main())
